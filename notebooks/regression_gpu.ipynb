{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, Ridge, Lasso, ElasticNet\n",
    "\n",
    "import warnings\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from cuml.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "data_df = cudf.read_csv(\"../data/data.csv\")\n",
    "billboard_df = cudf.read_csv(\"../data/billboard/hot-100_all.csv\")\n",
    "pop_metrics = cudf.read_csv(\"../data/popularity_metrics.csv\")\n",
    "\n",
    "data_df.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "pop_metrics.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "pop_metrics['avg_rank_score'] = pop_metrics['avg_rank_score'].apply(lambda x: x*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "cudf.core.dataframe.DataFrame"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   title  \\\n0        All I Want For Christmas Is You   \n1      Rockin' Around The Christmas Tree   \n2                       Jingle Bell Rock   \n3                A Holly Jolly Christmas   \n4                                Circles   \n...                                  ...   \n10495                             Bubbly   \n10496                        Do It To It   \n10497                            No Love   \n10498                        Knowing You   \n10499                        Family Ties   \n\n                                     artist image  peakPos  lastPos  weeks  \\\n0                              Mariah Carey  <NA>        1        1     37   \n1                                Brenda Lee  <NA>        2        2     32   \n2                               Bobby Helms  <NA>        3        9     30   \n3                                 Burl Ives  <NA>        4        6     15   \n4                               Post Malone  <NA>        1        3     17   \n...                                     ...   ...      ...      ...    ...   \n10495  Young Thug With Drake & Travis Scott  <NA>       20      100     10   \n10496              Acraze Featuring Cherish  <NA>       97        0      1   \n10497                   Summer Walker & SZA  <NA>       13       96      7   \n10498                         Kenny Chesney  <NA>       57       84     19   \n10499            Baby Keem & Kendrick Lamar  <NA>       18       93     17   \n\n       rank  isNew        date  \n0         1  False  2020-01-04  \n1         2  False  2020-01-04  \n2         3  False  2020-01-04  \n3         4  False  2020-01-04  \n4         5  False  2020-01-04  \n...     ...    ...         ...  \n10495    96  False  2022-01-01  \n10496    97   True  2022-01-01  \n10497    98  False  2022-01-01  \n10498    99  False  2022-01-01  \n10499   100  False  2022-01-01  \n\n[10500 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>artist</th>\n      <th>image</th>\n      <th>peakPos</th>\n      <th>lastPos</th>\n      <th>weeks</th>\n      <th>rank</th>\n      <th>isNew</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>All I Want For Christmas Is You</td>\n      <td>Mariah Carey</td>\n      <td>&lt;NA&gt;</td>\n      <td>1</td>\n      <td>1</td>\n      <td>37</td>\n      <td>1</td>\n      <td>False</td>\n      <td>2020-01-04</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rockin' Around The Christmas Tree</td>\n      <td>Brenda Lee</td>\n      <td>&lt;NA&gt;</td>\n      <td>2</td>\n      <td>2</td>\n      <td>32</td>\n      <td>2</td>\n      <td>False</td>\n      <td>2020-01-04</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jingle Bell Rock</td>\n      <td>Bobby Helms</td>\n      <td>&lt;NA&gt;</td>\n      <td>3</td>\n      <td>9</td>\n      <td>30</td>\n      <td>3</td>\n      <td>False</td>\n      <td>2020-01-04</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A Holly Jolly Christmas</td>\n      <td>Burl Ives</td>\n      <td>&lt;NA&gt;</td>\n      <td>4</td>\n      <td>6</td>\n      <td>15</td>\n      <td>4</td>\n      <td>False</td>\n      <td>2020-01-04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Circles</td>\n      <td>Post Malone</td>\n      <td>&lt;NA&gt;</td>\n      <td>1</td>\n      <td>3</td>\n      <td>17</td>\n      <td>5</td>\n      <td>False</td>\n      <td>2020-01-04</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10495</th>\n      <td>Bubbly</td>\n      <td>Young Thug With Drake &amp; Travis Scott</td>\n      <td>&lt;NA&gt;</td>\n      <td>20</td>\n      <td>100</td>\n      <td>10</td>\n      <td>96</td>\n      <td>False</td>\n      <td>2022-01-01</td>\n    </tr>\n    <tr>\n      <th>10496</th>\n      <td>Do It To It</td>\n      <td>Acraze Featuring Cherish</td>\n      <td>&lt;NA&gt;</td>\n      <td>97</td>\n      <td>0</td>\n      <td>1</td>\n      <td>97</td>\n      <td>True</td>\n      <td>2022-01-01</td>\n    </tr>\n    <tr>\n      <th>10497</th>\n      <td>No Love</td>\n      <td>Summer Walker &amp; SZA</td>\n      <td>&lt;NA&gt;</td>\n      <td>13</td>\n      <td>96</td>\n      <td>7</td>\n      <td>98</td>\n      <td>False</td>\n      <td>2022-01-01</td>\n    </tr>\n    <tr>\n      <th>10498</th>\n      <td>Knowing You</td>\n      <td>Kenny Chesney</td>\n      <td>&lt;NA&gt;</td>\n      <td>57</td>\n      <td>84</td>\n      <td>19</td>\n      <td>99</td>\n      <td>False</td>\n      <td>2022-01-01</td>\n    </tr>\n    <tr>\n      <th>10499</th>\n      <td>Family Ties</td>\n      <td>Baby Keem &amp; Kendrick Lamar</td>\n      <td>&lt;NA&gt;</td>\n      <td>18</td>\n      <td>93</td>\n      <td>17</td>\n      <td>100</td>\n      <td>False</td>\n      <td>2022-01-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>10500 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def gscv(mdl, param_grid, x_, y_, score_method, verbose=0):\n",
    "    grid_search = GridSearchCV(mdl, param_grid=param_grid, n_jobs=-1, verbose=verbose, scoring=score_method)\n",
    "    grid_search.fit(x_, y_)\n",
    "    if verbose == 1:\n",
    "        print(f\"best params = {grid_search.best_params_}\")\n",
    "        print(f\"best score = {grid_search.best_score_}\")\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def process_subset(model, X, y, features):\n",
    "    kf = KFold()\n",
    "    mse = []\n",
    "    X = X[list(features)]\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        regr = model.fit(X_train, y=y_train)\n",
    "        y_predict = regr.predict(X_test)\n",
    "        mse.append(mean_squared_error(y_test, y_predict))\n",
    "    return {\"model\": model, \"features\": features, \"MSE\":cp.mean(mse)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def best_subset(model, X, y, subset_size=-1, force=False):\n",
    "    limit = 100000\n",
    "    if subset_size == -1:\n",
    "        subset_size = len(X.columns)\n",
    "    assert len(X.columns) >= subset_size, f\"X.columns must be >= subset_size. Given len(X.columns)={len(X.columns)}, subset_size={subset_size}\"\n",
    "\n",
    "    num_combinations = cp.math.factorial(len(X.columns))/(cp.math.factorial(len(X.columns)-subset_size) * cp.math.factorial(subset_size))\n",
    "    if num_combinations > limit and not force:\n",
    "        print(f\"Please be aware that this action will run {int(num_combinations)} models and there is a real possibility it will crash your system.\\nIf you're ABSOLUTELY SURE you want to do this please include the parameter 'force=True' when calling this function\")\n",
    "        return {\"model\": model, \"features\": X.columns, \"MSE\": -1}\n",
    "    tic = time.time()\n",
    "    results = []\n",
    "    for combo in itertools.combinations(X.columns, subset_size):\n",
    "        results.append(process_subset(model, X, y, combo))\n",
    "    models = cudf.DataFrame(results)\n",
    "    best_model = models.loc[models['MSE'].argmin()]\n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", subset_size, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    return best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def stepwise_selection(model, X, y, direction='forward', num_features=None, scoring='neg_root_mean_squared_error'):\n",
    "    sfs = SequentialFeatureSelector(model, direction=direction, n_features_to_select=num_features, scoring=scoring)\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    sfs.fit(X, y)\n",
    "    return sfs.transform(X), sfs.get_support()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "# get n samples from 1-dimensional df following a gaussian distribution\n",
    "def sample(df: cudf.DataFrame, n=400, plot=False):\n",
    "    x = cp.sort(df)\n",
    "    f_x = cp.gradient(x)*cp.exp(-x**2/2)\n",
    "    sample_probs = f_x/cp.sum(f_x)\n",
    "    df_samples = df.sort_values().sample(n=n, weights=sample_probs, replace=False)\n",
    "    if plot:\n",
    "        sns.distplot(df_samples)\n",
    "    return df_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mask(item, mask):\n",
    "    final = []\n",
    "    for i in range(len(item)):\n",
    "        if mask[i] == True:\n",
    "            final.append(item[i])\n",
    "    return final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sample(pop_metrics['avg_rank_score'], plot=True)\n",
    "# features, idx_mask = stepwise_selection(Ridge(), data_df, pop_metrics['avg_rank_score'], num_features=2)\n",
    "# fs = data_df.loc[:, idx_mask==True]\n",
    "# fs = data_df.masked_assign(True, idx_mask)\n",
    "cols = data_df.columns[0]\n",
    "to_drop = []\n",
    "for idx, i in enumerate(idx_mask):\n",
    "    if i == True:\n",
    "        to_drop.append(data_df.columns[idx])\n",
    "data_df.drop(labels=to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# features, idx_mask = stepwise_selection(LinearRegression(), data_df, pop_metrics['avg_rank_score'], direction='backward')\n",
    "# bs = data_df.loc[:, idx_mask==True]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "def run_regression(model, X, y):\n",
    "    mse = []\n",
    "    for train_idx, test_idx in KFold().split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        regr = model.fit(X_train, y=y_train)\n",
    "        y_predict = regr.predict(X_test)\n",
    "        mse.append(mean_squared_error(y_test, y_predict))\n",
    "    return cp.mean(mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def run(mdl, X: cudf.DataFrame, y, forward=True, backward=True):\n",
    "    tic = time.time()\n",
    "    results = []\n",
    "    if forward:\n",
    "        for f in range(1, len(X.columns)):\n",
    "            _, predictors_mask = stepwise_selection(mdl['model'], X, y, direction='forward', num_features=f)\n",
    "            predictors = X.loc[:, predictors_mask==True]\n",
    "            best_params, best_score = gscv(mdl['model'], mdl['cv'], predictors, y, score_method='neg_root_mean_squared_error', verbose=0)\n",
    "            results.append({\"model\": mdl['model'], \"best_parms\": best_params, \"best_score\": best_score, \"features\": predictors.columns, \"features_mask\": predictors_mask, \"feature_selection_method\": \"forward_selection\", \"num_features\": f})\n",
    "\n",
    "    if backward:\n",
    "        for f in range(cp.arange(1, len(X.columns))):\n",
    "            _, predictors_mask = stepwise_selection(mdl['model'], X, y, direction='backward', num_features=f)\n",
    "            predictors = X.loc[:, predictors_mask==True]\n",
    "            best_params, best_score = gscv(mdl['model'], mdl['cv'], predictors, y, score_method='neg_root_mean_squared_error', verbose=0)\n",
    "            results.append({\"model\": mdl['model'], \"best_parms\": best_params, \"best_score\": best_score, \"features\": predictors.columns, \"features_mask\": predictors_mask, \"feature_selection_method\": \"backward_selection\", \"num_features\": f})\n",
    "\n",
    "    best_params, best_score = gscv(mdl['model'], mdl['cv'], X, y, score_method='neg_root_mean_squared_error', verbose=0)\n",
    "    results.append({\"model\": mdl['model'], \"best_parms\": best_params, \"best_score\": best_score, \"features\": X.columns, \"features_mask\": [], \"feature_selection_method\": \"none\", \"num_features\": -1})\n",
    "\n",
    "    toc = time.time()\n",
    "\n",
    "    print(f\"Processed {len(results)} in {toc-tic} seconds.\")\n",
    "    return results\n",
    "\n",
    "# y = sample(pop_metrics['avg_rank_score'], plot=False)\n",
    "# X = data_df.iloc[y.index]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "# mdl = RidgeCV(scoring='neg_root_mean_squared_error').fit(x_train, y_train)\n",
    "# y_pred = mdl.predict(x_test)\n",
    "# print(f\"mse: {mean_squared_error(y_test, y_pred)}\")\n",
    "# fig = plt.figure(figsize=(10,5))\n",
    "# plt.scatter(y_test,y_pred)\n",
    "# plt.plot(y_test,y_test,'r', label='test')\n",
    "# plt.plot(y_pred,y_pred,'b', label='pred')\n",
    "# plt.show()\n",
    "#\n",
    "# # y = sample(pop_metrics['avg_rank_score'], plot=False)\n",
    "# X = fs.iloc[y.index]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "# mdl = RidgeCV(scoring='neg_root_mean_squared_error').fit(x_train, y_train)\n",
    "# y_pred = mdl.predict(x_test)\n",
    "# print(f\"mse: {mean_squared_error(y_test, y_pred)}\")\n",
    "# fig = plt.figure(figsize=(10,5))\n",
    "# plt.scatter(y_test,y_pred)\n",
    "# plt.plot(y_test,y_test,'r', label='test')\n",
    "# plt.plot(y_pred,y_pred,'b', label='pred')\n",
    "#\n",
    "# # y = sample(pop_metrics['avg_rank_score'], plot=False)\n",
    "# X = bs.iloc[y.index]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "# mdl = RidgeCV(scoring='neg_root_mean_squared_error').fit(x_train, y_train)\n",
    "# y_pred = mdl.predict(x_test)\n",
    "# print(f\"mse: {mean_squared_error(y_test, y_pred)}\")\n",
    "# fig = plt.figure(figsize=(10,5))\n",
    "# plt.scatter(y_test,y_pred)\n",
    "# plt.plot(y_test,y_test,'r', label='test')\n",
    "# plt.plot(y_pred,y_pred,'b', label='pred')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 1067",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_183/1839817274.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpop_metrics\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         all_models.append({\n\u001B[0;32m---> 15\u001B[0;31m             \u001B[0;34m\"results\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackward\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"X_test\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"y_test\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         })\n",
      "\u001B[0;32m/tmp/ipykernel_183/2174471817.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(mdl, X, y, forward, backward)\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m             \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictors_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstepwise_selection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmdl\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdirection\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'forward'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_features\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m             \u001B[0mpredictors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictors_mask\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m             \u001B[0mbest_params\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbest_score\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgscv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmdl\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmdl\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'cv'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscore_method\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'neg_root_mean_squared_error'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_183/3598492197.py\u001B[0m in \u001B[0;36mstepwise_selection\u001B[0;34m(model, X, y, direction, num_features, scoring)\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0msfs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mcp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msfs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msfs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_support\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32mcupy/_core/core.pyx\u001B[0m in \u001B[0;36mcupy._core.core.ndarray.__init__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: maximum supported dimension for an ndarray is 32, found 1067"
     ]
    }
   ],
   "source": [
    "model_configs = {\n",
    "    \"models\": [\n",
    "        {\"model\": Ridge(), \"cv\": {}},\n",
    "        {\"model\": Lasso(max_iter=10000), \"cv\": {}},\n",
    "        {\"model\": ElasticNet(max_iter=10000), \"cv\": {}}\n",
    "    ],\n",
    "    \"y\": ['avg_rank_score'],\n",
    "}\n",
    "\n",
    "all_models = []\n",
    "for m in model_configs['models']:\n",
    "    for y in model_configs['y']:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_df, pop_metrics[y])\n",
    "        all_models.append({\n",
    "            \"results\": run(m, X_train, y_train, forward=True, backward=True), \"X_test\": X_test, \"y_test\": y_test\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}