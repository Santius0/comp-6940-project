{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import billboard\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import animation\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import spotipy\n",
    "from spotipy import SpotifyClientCredentials\n",
    "# from spotipy.oauth2 import SpotifyOAuth\n",
    "from dotenv import load_dotenv\n",
    "import string\n",
    "\n",
    "from ytmusicapi import YTMusic\n",
    "from pytube import YouTube as YTDownload\n",
    "import re\n",
    "import requests\n",
    "import wget\n",
    "import time\n",
    "from math import floor\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cupy as cp\n",
    "# import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "load_dotenv('../.env')\n",
    "scope = \"user-library-read\"\n",
    "\n",
    "spotify = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=os.environ.get('SPOTIPY_CLIENT_ID'),\n",
    "                                                                client_secret=os.environ.get('SPOTIPY_CLIENT_SECRET')))\n",
    "# spotify = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def all_day_in_year(day=0, year=date.today().year):\n",
    "    \"\"\"Returns every occurrence of a specified weekday in a specified year\"\"\"\n",
    "\n",
    "    # yyyy mm dd\n",
    "    # 0 = mon\n",
    "    # 1 = tue\n",
    "    # 2 = wed\n",
    "    # 3 = thu\n",
    "    # 4 = fri\n",
    "    # 5 = sat\n",
    "    # 6 = sun\n",
    "    dte = date(year, 1, 1)\n",
    "    dte += timedelta(days=(day - dte.weekday()) % 7)\n",
    "    while dte.year == year:\n",
    "        yield dte\n",
    "        dte += timedelta(days=7)\n",
    "\n",
    "def get_chart(chart_title='hot-100', week=date.today(), starting_id=0):\n",
    "    chart = billboard.ChartData(chart_title, date=week, max_retries=10, fetch=True)\n",
    "    return pd.DataFrame(data=[[\n",
    "        # starting_id + idx,\n",
    "        #                        song.title,\n",
    "                               song.artist,\n",
    "                               song.image,\n",
    "                               song.peakPos,\n",
    "                               song.lastPos,\n",
    "                               song.weeks,\n",
    "                               song.rank,\n",
    "                               song.isNew,\n",
    "                               chart.date] for idx, song in enumerate(chart)],\n",
    "                        columns=[\n",
    "                            # 'id',\n",
    "                            #      'title',\n",
    "                                 'artist',\n",
    "                                 'image',\n",
    "                                 'peakPos',\n",
    "                                 'lastPos',\n",
    "                                 'weeks',\n",
    "                                 'rank',\n",
    "                                 'isNew',\n",
    "                                 'date'], index=[song.title for song in chart]), starting_id + len(chart)\n",
    "\n",
    "@animation.wait('spinner', text='Fetching Billboard Charts', speed=0.2)\n",
    "def get_billboard_data(start_year, end_year, chart_title='hot-100', output_dir=os.getcwd()):\n",
    "    state_cols = ['last_date', 'last_id', 'next_id', 'num_weeks', 'num_songs']\n",
    "    default_state = [[None, 0, 0, 0, 0]]\n",
    "    output_path = mkdir(f\"{output_dir}/{chart_title}\")\n",
    "    year = end_year\n",
    "    while year >= start_year:\n",
    "        for week in all_day_in_year(4, year):\n",
    "            state_df= pd.read_csv(f'{output_path}/state.csv') if os.path.exists(f'{output_path}/state.csv') else \\\n",
    "                pd.DataFrame(data=default_state, columns=state_cols)\n",
    "            next_id = state_df.iloc[0]['next_id']\n",
    "            num_weeks = state_df.iloc[0]['num_weeks']\n",
    "            num_songs = state_df.iloc[0]['num_songs']\n",
    "            chart_df, last_id = get_chart(chart_title=chart_title, week=week, starting_id=next_id)\n",
    "            state_df.update(pd.DataFrame(data=[[week, last_id-1, last_id, num_weeks+1, num_songs+(last_id-next_id)]], columns=state_cols))\n",
    "            state_df.to_csv(f\"{output_path}/state.csv\", index=False)\n",
    "            chart_df.to_csv(f\"{output_path}/{chart_title}_{week}.csv\", index_label='title')\n",
    "        year -= 1\n",
    "    print(f\"Data written to {output_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def merge_csvs_in_path(path, glob_pattern=\"hot-100_*.csv\", output_path='../data/billboard', output_filename='merged_csv', index=False):\n",
    "    files = glob.glob(f'{os.path.abspath(path)}/{glob_pattern}')\n",
    "    full_df = None\n",
    "    for file in files:\n",
    "        full_df = pd.read_csv(file) if full_df is None else pd.concat([full_df, pd.read_csv(file)])\n",
    "    full_df.to_csv(f\"{output_path}/{output_filename}.csv\", index=index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_song_data(title, artist=None):\n",
    "    # get results with only song name\n",
    "    title = title.replace(\"$\", \"s\")\n",
    "    results = spotify.search(q='track:' + title, type='track')['tracks']['items']\n",
    "    # if that doesn't work get results with song name and first artist\n",
    "    if len(results) == 0:\n",
    "        artist = ' ' + artist.lower().split('featuring')[0] if artist else ''\n",
    "        results = spotify.search(q='track:' + title + artist, type='track')['tracks']['items']\n",
    "        # if that doesn't work return None\n",
    "        if len(results) == 0:\n",
    "            return None, None, None\n",
    "    song_data = results[0]\n",
    "    artists = spotify.artists([ar['id'] for ar in song_data['artists']][:50])\n",
    "    song_data['artist_popularity'] = [ar['popularity'] for ar in artists['artists']]\n",
    "    artist_genres = []\n",
    "    for ag in [ar['genres'] for ar in artists['artists']]:\n",
    "        artist_genres += ag\n",
    "    song_data['artist_genres'] = list(dict.fromkeys(artist_genres))\n",
    "    audio_features = spotify.audio_features([song_data['id']])\n",
    "    try:\n",
    "        audio_analysis = spotify.audio_analysis(song_data['id'])\n",
    "    except spotipy.SpotifyException:\n",
    "        audio_analysis = None\n",
    "\n",
    "    return song_data, audio_features[0], audio_analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def remove_punctuation(val: str) -> str:\n",
    "    return val.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def mkdir(path: str) -> str:\n",
    "    path = os.path.abspath(path)\n",
    "    os.makedirs(path) if not os.path.exists(path) else None\n",
    "    return path\n",
    "\n",
    "def open_or_create_csv(path, cols):\n",
    "    path = os.path.abspath(path)\n",
    "    dir = os.sep.join(path.split(os.sep)[:-1])\n",
    "    os.makedirs(dir) if not os.path.exists(dir) else None\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        pd.DataFrame(columns=cols).to_csv(path, index=False)\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "@animation.wait('spinner', text='Fetching Spotify Song Data', speed=0.2)\n",
    "def fetch_spotify_songs(song_dir, glob_pattern='*', output_dir='./', output_file='songs.csv', audio_analysis_dir=None, preview_audio_dir='../data/audio/previews', preview_format=\"m4a\", verbose=False):\n",
    "    state_cols = ['billboard_name', 'spotify_name', 'song_data', 'audio_features', 'audio_analysis']\n",
    "    spotify_song_cols = ['billboard_name', 'spotify_name', 'artist', 'duration_ms', 'spotify_id', 'spotify_uri', 'spotify_external_url', 'spotify_popularity', 'spotify_artist_popularity', 'spotify_artist_popularity_mean', 'explicit', 'preview_url', 'preview_url_audio', 'full_audio', 'full_audio_duration_s', 'artist_genres']\n",
    "    audio_feature_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
    "    audio_analysis_cols = ['audio_analysis_file']\n",
    "    song_dir = os.path.abspath(song_dir)\n",
    "    audio_analysis_dir = os.path.abspath(audio_analysis_dir) if audio_analysis_dir is not None else f\"{output_dir}/audio_analysis\"\n",
    "    audio_analysis_dir = mkdir(audio_analysis_dir)\n",
    "    path_glob = glob.glob(f\"{song_dir}/{glob_pattern}\")\n",
    "    # output_dir = os.path.abspath(output_dir)\n",
    "    output_dir = mkdir(output_dir)\n",
    "    # preview_audio_dir = os.path.abspath(preview_audio_dir)\n",
    "    preview_audio_dir = mkdir(preview_audio_dir)\n",
    "    for file in path_glob:\n",
    "        weeks_songs = pd.read_csv(file)\n",
    "        spotify_songs_df = open_or_create_csv(f'{output_dir}/{output_file}', spotify_song_cols)\n",
    "        for i in range(len(weeks_songs)):\n",
    "            song = weeks_songs.iloc[i]\n",
    "            spotify_song = spotify_songs_df.loc[spotify_songs_df['billboard_name'] == song['title']]\n",
    "            if spotify_song.empty:\n",
    "                # if empty get song data\n",
    "                song_data, audio_features, audio_analysis = get_song_data(song['title'], artist=song['artist'])\n",
    "                state = [song['title']]\n",
    "\n",
    "                if song_data is not None:\n",
    "                    state.append(song_data['name'])\n",
    "                    state.append(True)\n",
    "                    s_df = pd.DataFrame(data=[[\n",
    "                        song['title'],\n",
    "                        song_data['name'],\n",
    "                        song['artist'],\n",
    "                        song_data['duration_ms'],\n",
    "                        song_data['id'],\n",
    "                        song_data['uri'],\n",
    "                        song_data['external_urls']['spotify'],\n",
    "                        song_data['popularity'],\n",
    "                        song_data['artist_popularity'],\n",
    "                        sum(song_data['artist_popularity'])/len(song_data['artist_popularity']),\n",
    "                        song_data['explicit'],\n",
    "                        song_data['preview_url'],\n",
    "                         wget.download(song_data['preview_url'], out=f\"{preview_audio_dir}/{remove_punctuation(song['title'])}.{preview_format}\").split(os.sep)[-1] if song_data['preview_url'] else None,\n",
    "                        \"not_fetched\",\n",
    "                        -1,\n",
    "                        song_data['artist_genres']]], columns=spotify_song_cols)\n",
    "                else:\n",
    "                    state.append(None)\n",
    "                    state.append(False)\n",
    "                    s_df = pd.DataFrame(data=[[song['title']] + [None for i in range(len(spotify_song_cols)-1)]], columns=spotify_song_cols)\n",
    "\n",
    "                if audio_features is not None:\n",
    "                    state.append(True)\n",
    "                    # audio_feature_cols = ['spotify_' + item for item in audio_feature_cols]\n",
    "                    af_df = pd.DataFrame(data=[[audio_features['danceability'],\n",
    "                                                audio_features['energy'],\n",
    "                                                audio_features['key'],\n",
    "                                                audio_features['loudness'],\n",
    "                                                audio_features['mode'],\n",
    "                                                audio_features['speechiness'],\n",
    "                                                audio_features['acousticness'],\n",
    "                                                audio_features['instrumentalness'],\n",
    "                                                audio_features['liveness'],\n",
    "                                                audio_features['valence'],\n",
    "                                                audio_features['tempo'],\n",
    "                                                audio_features['time_signature']]], columns=audio_feature_cols)\n",
    "                    # af_df = pd.DataFrame(data=[['sample feature 1']], columns=['audio_feature_1'])\n",
    "                else:\n",
    "                    state.append(False)\n",
    "                    af_df = pd.DataFrame(data=[[None for i in range(len(audio_feature_cols))]], columns=audio_feature_cols)\n",
    "\n",
    "                if audio_analysis is not None:\n",
    "                    state.append(True)\n",
    "                    song_title = remove_punctuation(song['title'])\n",
    "                    with open(f\"{audio_analysis_dir}/{song_title}.json\", \"w+\", encoding=\"utf-8\") as json_file:\n",
    "                        json.dump(audio_analysis, json_file, ensure_ascii=False, indent=4)\n",
    "                        aa_df = pd.DataFrame(data=[[f\"{song_title}.json\"]], columns=audio_analysis_cols)\n",
    "                    # aa_df = pd.DataFrame(data=[['sample analysis 1']], columns=['audio_analysis_1'])\n",
    "                else:\n",
    "                    state.append(False)\n",
    "                    aa_df = pd.DataFrame(data=[[None for i in range(len(audio_analysis_cols))]], columns=audio_analysis_cols)\n",
    "                    # aa_df = pd.DataFrame(data=[['sample analysis 1 EMPTY']], columns=['audio_analysis_1'])\n",
    "\n",
    "                s_df = pd.concat([s_df, af_df, aa_df], axis=1)\n",
    "                spotify_songs_df = pd.concat([spotify_songs_df, s_df])\n",
    "                spotify_songs_df.to_csv(f'{output_dir}/{output_file}', index=False)\n",
    "                state_df = open_or_create_csv(f'{output_dir}/state.csv', cols=state_cols)\n",
    "                state_df = pd.concat([state_df, pd.DataFrame(data=[state], columns=state_cols)])\n",
    "                state_df.to_csv(f'{output_dir}/state.csv', index=False)\n",
    "            elif verbose:\n",
    "                print(f\"{spotify_song.iloc[0]['billboard_name']} - {song['artist']} skipped...\")\n",
    "    print(f\"Data written to {output_file}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def yt_get_query_string(song_name: str) ->  bytes:\n",
    "    return \"+\".join(song_name.split()).encode(\"utf-8\")\n",
    "\n",
    "def yt_query(video_title: str, all_ids: bool = False) -> str or None:\n",
    "    query = yt_get_query_string(video_title)\n",
    "    url = f\"https://www.youtube.com/results?search_query={query}\"\n",
    "    html = requests.get(url)\n",
    "    vid_ids = re.findall(r\"watch\\?v=(\\S{11})\", html.text)\n",
    "    if len(vid_ids) == 0: return None\n",
    "    return vid_ids if all_ids else vid_ids[0]\n",
    "\n",
    "def yt_download_audio(vid_id: str, output_dir=os.getcwd(), filename=None, file_type='m4a') -> str or None:\n",
    "    yt_music = YTMusic()\n",
    "    track = yt_music.get_song(videoId=vid_id)\n",
    "    song_url = track['microformat']['microformatDataRenderer']['urlCanonical']\n",
    "    vid = YTDownload(song_url)\n",
    "    vid_audio = vid.streams.get_audio_only()\n",
    "    if vid_audio is None: return None\n",
    "    filename = track['videoDetails']['title'] if filename is None else filename\n",
    "    filename = remove_punctuation(filename)\n",
    "    output_dir = mkdir(output_dir)\n",
    "    return vid_audio.download(output_path=output_dir, filename=f\"{filename}.{file_type}\"), track['videoDetails']['lengthSeconds']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "@animation.wait('spinner', text='Fetching Audio Files', speed=0.2)\n",
    "def fetch_audio_data(songs_csv_filepath=\"../data/spotify/songs.csv\", output_dir=\"../data/audio/full\"):\n",
    "    songs_csv_filepath = os.path.abspath(songs_csv_filepath)\n",
    "    output_dir = mkdir(output_dir)\n",
    "    songs_df_full = pd.read_csv(songs_csv_filepath)\n",
    "    songs_df = songs_df_full[['billboard_name', 'artist', 'full_audio']]\n",
    "    try:\n",
    "        for i in range(len(songs_df)):\n",
    "            song = songs_df.iloc[i]\n",
    "            if song['full_audio'] == \"not_fetched\":\n",
    "                query_string = f\"{song['billboard_name']} {song['artist']} lyrics\"\n",
    "                yt_id = yt_query(query_string, all_ids=False)\n",
    "                # print(f\"{song['billboard_name']}: {yt_id}\")\n",
    "                audio_file, duration_s = yt_download_audio(yt_id, output_dir=output_dir) if yt_id is not None else (None, None)\n",
    "                songs_df_full.iat[i, songs_df_full.columns.get_loc('full_audio')] = audio_file.split(os.sep)[-1]\n",
    "                songs_df_full.iat[i, songs_df_full.columns.get_loc('full_audio_duration_s')] = duration_s\n",
    "    except Exception:\n",
    "        songs_df_full.to_csv(songs_csv_filepath, index=False)\n",
    "    finally:\n",
    "        songs_df_full.to_csv(songs_csv_filepath, index=False)\n",
    "    print(f\"Data written to {output_dir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Billboard Charts\t/Data written to C:\\msc_data_science_uwi_sta\\semester_2\\classes\\comp_6940\\project\\comp-6940-project\\data\\billboard\\hot-100\n",
      "\u001B[K\n"
     ]
    }
   ],
   "source": [
    "get_billboard_data(2020, 2021, output_dir=\"../data/billboard\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "merge_csvs_in_path('../data/billboard/hot-100', glob_pattern='hot-100_*.csv', output_path='../data/billboard', output_filename='hot-100_all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Spotify Song Data\t\\"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error for GET to https://api.spotify.com/v1/audio-analysis/4LaGu95Ui2s4vprSQYWUAZ with Params: {} returned 404 due to analysis not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Data written to songs.csv\n",
      "\u001B[K\n"
     ]
    }
   ],
   "source": [
    "fetch_spotify_songs(song_dir=\"../data/billboard/hot-100/\", glob_pattern=\"hot-100_*.csv\", output_dir='../data/spofity', output_file='songs.csv', audio_analysis_dir='../data/spofity/audio_analysis', preview_audio_dir=\"../data/audio/previews\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Audio Files\t|Data written to C:\\msc_data_science_uwi_sta\\semester_2\\classes\\comp_6940\\project\\comp-6940-project\\data\\audio\\full\n",
      "\u001B[K\n"
     ]
    }
   ],
   "source": [
    "fetch_audio_data(\"../data/spofity/songs.csv\", output_dir=\"../data/audio/full\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6874.429597616196 seconds\n",
      "114 mins, 34.42959761619568 seconds\n"
     ]
    }
   ],
   "source": [
    "execution_time = time.time() - start_time\n",
    "print(f\"{execution_time} seconds\\n{floor(execution_time/60)} mins, {execution_time%60} seconds\")\n",
    "# execution time to get Billboard charts, Spotify data and YouTube audio data for 2020 and 2021\n",
    "#                = 4776.834360599518 seconds\n",
    "#                = 79 mins, 36.83436059951782 seconds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features to extract (modelled off GTZAN dataset):\n",
    "    0. length of analysed segments\n",
    "    1. Chroma stft (short term fourier transform)\n",
    "    2. rms (root mean square)\n",
    "    3. spectral centroid\n",
    "    4. spectral bandwidth\n",
    "    5. rolloff\n",
    "    6. zero crossing rate\n",
    "    7. harmony\n",
    "    8. perceptr\n",
    "    9. tempo\n",
    "    10. mfccs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def extract_audio_features(filepath:str, chunk_length: float or int = None, num_chunks: int = 1, n_fft:int=2048, hop_length:int=512):\n",
    "    assert ((num_chunks > 1) and (chunk_length is not None)) == False, \"either chunk_length or num_chunks must be used\"\n",
    "    assert num_chunks > 0, \"num chunks cannot be negative\"\n",
    "\n",
    "    filepath = os.path.abspath(filepath)\n",
    "    filename = filepath.split(os.sep)[-1]\n",
    "    y, sample_rate = librosa.load(filepath)\n",
    "    duration_s = np.shape(y)[0]/sample_rate\n",
    "\n",
    "    if chunk_length:\n",
    "        num_chunks = int(np.ceil(duration_s/chunk_length))\n",
    "    if num_chunks > 1: chunk_length = duration_s/num_chunks\n",
    "    else: chunk_length = duration_s\n",
    "\n",
    "    final_df = None\n",
    "    cols = []\n",
    "    for chunk in range(num_chunks):\n",
    "        name = filename if num_chunks == 1 else f\"{filename}_{chunk}\"\n",
    "        offset = chunk_length * chunk\n",
    "        audio, sr = librosa.load(filepath, offset=offset, duration=chunk_length)\n",
    "        audio, _ = librosa.effects.trim(audio)\n",
    "        # stft = np.abs(librosa.stft(audio, n_fft=n_fft, hop_length=hop_length))\n",
    "        chroma_stft = librosa.feature.chroma_stft(audio, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
    "        chroma_stft_mean = np.mean(chroma_stft)\n",
    "        chroma_stft_var = np.var(chroma_stft)\n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        rms_mean = np.mean(rms)\n",
    "        rms_var = np.var(rms)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(audio, sr=sr)[0]\n",
    "        spectral_centroid_mean = np.mean(spectral_centroid)\n",
    "        spectral_centroid_var = np.var(spectral_centroid)\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(audio)\n",
    "        spectral_bandwidth_mean = np.mean(spectral_bandwidth)\n",
    "        spectral_bandwidth_var = np.var(spectral_bandwidth)\n",
    "        rolloff = librosa.feature.spectral_rolloff(audio)\n",
    "        rolloff_mean = np.mean(rolloff)\n",
    "        rolloff_var = np.mean(rolloff)\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)\n",
    "        zero_crossing_rate_mean = np.mean(zero_crossing_rate)\n",
    "        zero_crossing_rate_var = np.var(zero_crossing_rate)\n",
    "        harmony, perceptr = librosa.effects.hpss(audio)\n",
    "        harmony_mean = np.mean(harmony)\n",
    "        harmony_var = np.var(harmony)\n",
    "        perceptr_mean = np.mean(perceptr)\n",
    "        perceptr_var = np.var(perceptr)\n",
    "        tempo, _ = librosa.beat.beat_track(audio, sr=sr)\n",
    "        mfccs = librosa.feature.mfcc(audio, sr=sr)\n",
    "        mfccs_mean = [np.mean(mfcc) for mfcc in mfccs]\n",
    "        mfccs_var = [np.var(mfcc) for mfcc in mfccs]\n",
    "        cols = ['filename', 'length', 'chroma_stft_mean', 'chroma_stft_var', 'rms_mean', 'rms_var', 'spectral_centroid_mean', 'spectral_centroid_var', 'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'rolloff_mean', 'rolloff_var', 'zero_crossing_rate_mean', 'zero_crossing_rate_var', 'harmony_mean', 'harmony_var', 'perceptr_mean', 'perceptr_var', 'tempo']\n",
    "        data = [name, chunk_length, chroma_stft_mean, chroma_stft_var, rms_mean, rms_var, spectral_centroid_mean, spectral_centroid_var, spectral_bandwidth_mean, spectral_bandwidth_var, rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var, harmony_mean, harmony_var, perceptr_mean, perceptr_var, tempo]\n",
    "        for m in range(len(mfccs_mean)):\n",
    "            cols.append(f\"mfcc{m+1}_mean\")\n",
    "            cols.append(f\"mfcc{m+1}_var\")\n",
    "            data.append(mfccs_mean[m])\n",
    "            data.append(mfccs_var[m])\n",
    "        df = pd.DataFrame(columns=cols, data=[data])\n",
    "        final_df = df if final_df is None else pd.concat([final_df, df], axis=0)\n",
    "    return final_df, cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "@animation.wait('spinner', text='Fetching Audio Features', speed=0.2)\n",
    "def fetch_audio_features(song_path='../data/spofity/songs.csv', output_path='../data/audio/audio_features_full.csv', audio_dir='../data/audio/full', audio_type='full'):\n",
    "    assert audio_type == 'full' or audio_type == 'preview', 'audio_type must either be full or preview'\n",
    "    audio_field = \"full_audio\" if audio_type == \"full\" else 'preview_url_audio'\n",
    "    song_path = os.path.abspath(song_path)\n",
    "    output_path = os.path.abspath(output_path)\n",
    "    audio_dir = os.path.abspath(audio_dir)\n",
    "    songs_df = pd.read_csv(song_path)\n",
    "\n",
    "    status_dir = os.sep.join(output_path.split(os.sep)[:-1])\n",
    "    state_cols = ['billboard_name']\n",
    "    status_file = f\"{status_dir}/{audio_type}_state.csv\"\n",
    "    status_df = open_or_create_csv(status_file, state_cols)\n",
    "\n",
    "    for i in range(len(songs_df)):\n",
    "        filename = songs_df.iloc[i][audio_field]\n",
    "        if filename in status_df['billboard_name'].unique(): continue\n",
    "        filepath = f\"{audio_dir}/{filename}\"\n",
    "        audio_features, cols = extract_audio_features(filepath)\n",
    "        output_df = open_or_create_csv(output_path, cols)\n",
    "        output_df = pd.concat([output_df, audio_features])\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "        status_df = pd.concat([status_df, pd.DataFrame(data=[[filename]], columns=state_cols)])\n",
    "        status_df.to_csv(status_file, index=False)\n",
    "    output_df = open_or_create_csv(output_path, cols=[])\n",
    "    songs_df = pd.concat([songs_df, output_df], axis=1)\n",
    "    songs_df.to_csv(song_path, index=False)\n",
    "    return output_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fetch_audio_features('../data/spofity/songs.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Move function definitions to separate module"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}