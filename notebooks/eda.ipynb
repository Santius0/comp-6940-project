{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from utils.general import *\n",
    "\n",
    "import json\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "rng = np.random.default_rng(random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading And Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "outputs": [],
   "source": [
    "billboard_df = pd.read_csv(\"../data/billboard/hot-100_all.csv\")\n",
    "spotify_df = pd.read_csv(\"../data/spofity/songs.csv\")\n",
    "audio_analysis_df = pd.read_csv(\"../data/audio/audio_features_full.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "outputs": [],
   "source": [
    "billboard_df.drop(axis=1, inplace=True, labels=['image', 'artist'])\n",
    "billboard_df['date'] = pd.to_datetime(billboard_df['date'])\n",
    "spotify_df.drop(axis=1, inplace=True, labels=['spotify_name',\n",
    "                                              'artist',\n",
    "                                              'artist_genres',\n",
    "                                              'spotify_id',\n",
    "                                              'spotify_id',\n",
    "                                              'spotify_uri',\n",
    "                                              'spotify_external_url',\n",
    "                                              'spotify_artist_popularity',\n",
    "                                              'preview_url',\n",
    "                                              'preview_url_audio',\n",
    "                                              'full_audio',\n",
    "                                              'full_audio_duration_s'\n",
    "                                              ])\n",
    "audio_analysis_df.drop(axis=1, inplace=True, labels=['name', 'tempo'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "outputs": [
    {
     "data": {
      "text/plain": "                           billboard_name  duration_ms  spotify_popularity  \\\n0         All I Want For Christmas Is You     241106.0                69.0   \n1       Rockin' Around The Christmas Tree     126266.0                62.0   \n2                        Jingle Bell Rock     130973.0                62.0   \n3                 A Holly Jolly Christmas     135533.0                54.0   \n4                                 Circles     215280.0                86.0   \n...                                   ...          ...                 ...   \n1418  Christmas Isn't Canceled (Just You)     231549.0                41.0   \n1419                       Moved To Miami     222225.0                66.0   \n1420                              Hibachi     170413.0                69.0   \n1421                             Thailand     200958.0                70.0   \n1422                          Do It To It     157890.0                91.0   \n\n      spotify_artist_popularity_mean explicit  danceability  energy   key  \\\n0                          81.000000    False         0.336   0.627   7.0   \n1                          59.000000    False         0.589   0.472   8.0   \n2                          50.000000    False         0.754   0.424   2.0   \n3                          48.000000    False         0.683   0.375   0.0   \n4                          91.000000    False         0.695   0.762   0.0   \n...                              ...      ...           ...     ...   ...   \n1418                       77.000000    False         0.580   0.789   1.0   \n1419                       88.500000     True         0.717   0.444   1.0   \n1420                       86.333333     True         0.681   0.522   5.0   \n1421                       84.000000     True         0.875   0.478   7.0   \n1422                       78.000000    False         0.854   0.806  11.0   \n\n      loudness  mode  ...  mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  \\\n0       -7.463   1.0  ...     1.619618   99.735660    -3.865835   99.024666   \n1       -8.749   1.0  ...    -1.039626   78.420586    -4.437555   55.536427   \n2       -8.463   1.0  ...     1.430321   58.685158    -4.030815   67.332291   \n3      -13.056   1.0  ...    -1.355817   60.197350    -6.695084   52.782772   \n4       -3.497   1.0  ...     2.563944   78.141319   -12.359889   83.661438   \n...        ...   ...  ...          ...         ...          ...         ...   \n1418    -4.918   0.0  ...     5.321839   70.412506     1.213545   77.698616   \n1419   -11.126   1.0  ...     4.598643  180.801086    -4.373017  110.878738   \n1420    -8.740   0.0  ...     8.091636   79.854568    -1.646704  123.382797   \n1421   -10.562   1.0  ...    10.420262   91.743813    -2.071233   75.112267   \n1422    -8.262   0.0  ...     2.155907   68.733521    -5.703623   47.707085   \n\n      mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n0        2.729783  112.219580    -7.488522  122.569650     2.323859   \n1        3.890496   70.359543     0.014326   77.899239     6.889563   \n2        1.802275   58.469532    -5.335912   53.423290     0.133941   \n3       -4.325858   66.221947    -3.533713   50.849602    -1.266797   \n4        4.207565   65.643173    -5.280680   54.441185    -0.751733   \n...           ...         ...          ...         ...          ...   \n1418     4.693950   85.284431    -2.604682   76.687698     5.805956   \n1419     4.545245  111.550697     4.918246   63.780304     8.114554   \n1420     5.309008   98.507568     0.213412   80.767159     2.804790   \n1421     8.341298   97.730263    -0.260812   69.875168     1.959964   \n1422    -1.433100   45.689129    -6.835608   45.040623    -1.940495   \n\n      mfcc20_var  \n0     141.572560  \n1      93.610161  \n2      58.774597  \n3      90.991325  \n4      59.799530  \n...          ...  \n1418   77.433144  \n1419   75.806396  \n1420   73.490234  \n1421   62.722679  \n1422   51.794838  \n\n[1423 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>billboard_name</th>\n      <th>duration_ms</th>\n      <th>spotify_popularity</th>\n      <th>spotify_artist_popularity_mean</th>\n      <th>explicit</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>...</th>\n      <th>mfcc16_mean</th>\n      <th>mfcc16_var</th>\n      <th>mfcc17_mean</th>\n      <th>mfcc17_var</th>\n      <th>mfcc18_mean</th>\n      <th>mfcc18_var</th>\n      <th>mfcc19_mean</th>\n      <th>mfcc19_var</th>\n      <th>mfcc20_mean</th>\n      <th>mfcc20_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>All I Want For Christmas Is You</td>\n      <td>241106.0</td>\n      <td>69.0</td>\n      <td>81.000000</td>\n      <td>False</td>\n      <td>0.336</td>\n      <td>0.627</td>\n      <td>7.0</td>\n      <td>-7.463</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.619618</td>\n      <td>99.735660</td>\n      <td>-3.865835</td>\n      <td>99.024666</td>\n      <td>2.729783</td>\n      <td>112.219580</td>\n      <td>-7.488522</td>\n      <td>122.569650</td>\n      <td>2.323859</td>\n      <td>141.572560</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rockin' Around The Christmas Tree</td>\n      <td>126266.0</td>\n      <td>62.0</td>\n      <td>59.000000</td>\n      <td>False</td>\n      <td>0.589</td>\n      <td>0.472</td>\n      <td>8.0</td>\n      <td>-8.749</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>-1.039626</td>\n      <td>78.420586</td>\n      <td>-4.437555</td>\n      <td>55.536427</td>\n      <td>3.890496</td>\n      <td>70.359543</td>\n      <td>0.014326</td>\n      <td>77.899239</td>\n      <td>6.889563</td>\n      <td>93.610161</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jingle Bell Rock</td>\n      <td>130973.0</td>\n      <td>62.0</td>\n      <td>50.000000</td>\n      <td>False</td>\n      <td>0.754</td>\n      <td>0.424</td>\n      <td>2.0</td>\n      <td>-8.463</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.430321</td>\n      <td>58.685158</td>\n      <td>-4.030815</td>\n      <td>67.332291</td>\n      <td>1.802275</td>\n      <td>58.469532</td>\n      <td>-5.335912</td>\n      <td>53.423290</td>\n      <td>0.133941</td>\n      <td>58.774597</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A Holly Jolly Christmas</td>\n      <td>135533.0</td>\n      <td>54.0</td>\n      <td>48.000000</td>\n      <td>False</td>\n      <td>0.683</td>\n      <td>0.375</td>\n      <td>0.0</td>\n      <td>-13.056</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>-1.355817</td>\n      <td>60.197350</td>\n      <td>-6.695084</td>\n      <td>52.782772</td>\n      <td>-4.325858</td>\n      <td>66.221947</td>\n      <td>-3.533713</td>\n      <td>50.849602</td>\n      <td>-1.266797</td>\n      <td>90.991325</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Circles</td>\n      <td>215280.0</td>\n      <td>86.0</td>\n      <td>91.000000</td>\n      <td>False</td>\n      <td>0.695</td>\n      <td>0.762</td>\n      <td>0.0</td>\n      <td>-3.497</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.563944</td>\n      <td>78.141319</td>\n      <td>-12.359889</td>\n      <td>83.661438</td>\n      <td>4.207565</td>\n      <td>65.643173</td>\n      <td>-5.280680</td>\n      <td>54.441185</td>\n      <td>-0.751733</td>\n      <td>59.799530</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1418</th>\n      <td>Christmas Isn't Canceled (Just You)</td>\n      <td>231549.0</td>\n      <td>41.0</td>\n      <td>77.000000</td>\n      <td>False</td>\n      <td>0.580</td>\n      <td>0.789</td>\n      <td>1.0</td>\n      <td>-4.918</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5.321839</td>\n      <td>70.412506</td>\n      <td>1.213545</td>\n      <td>77.698616</td>\n      <td>4.693950</td>\n      <td>85.284431</td>\n      <td>-2.604682</td>\n      <td>76.687698</td>\n      <td>5.805956</td>\n      <td>77.433144</td>\n    </tr>\n    <tr>\n      <th>1419</th>\n      <td>Moved To Miami</td>\n      <td>222225.0</td>\n      <td>66.0</td>\n      <td>88.500000</td>\n      <td>True</td>\n      <td>0.717</td>\n      <td>0.444</td>\n      <td>1.0</td>\n      <td>-11.126</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>4.598643</td>\n      <td>180.801086</td>\n      <td>-4.373017</td>\n      <td>110.878738</td>\n      <td>4.545245</td>\n      <td>111.550697</td>\n      <td>4.918246</td>\n      <td>63.780304</td>\n      <td>8.114554</td>\n      <td>75.806396</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>Hibachi</td>\n      <td>170413.0</td>\n      <td>69.0</td>\n      <td>86.333333</td>\n      <td>True</td>\n      <td>0.681</td>\n      <td>0.522</td>\n      <td>5.0</td>\n      <td>-8.740</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>8.091636</td>\n      <td>79.854568</td>\n      <td>-1.646704</td>\n      <td>123.382797</td>\n      <td>5.309008</td>\n      <td>98.507568</td>\n      <td>0.213412</td>\n      <td>80.767159</td>\n      <td>2.804790</td>\n      <td>73.490234</td>\n    </tr>\n    <tr>\n      <th>1421</th>\n      <td>Thailand</td>\n      <td>200958.0</td>\n      <td>70.0</td>\n      <td>84.000000</td>\n      <td>True</td>\n      <td>0.875</td>\n      <td>0.478</td>\n      <td>7.0</td>\n      <td>-10.562</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>10.420262</td>\n      <td>91.743813</td>\n      <td>-2.071233</td>\n      <td>75.112267</td>\n      <td>8.341298</td>\n      <td>97.730263</td>\n      <td>-0.260812</td>\n      <td>69.875168</td>\n      <td>1.959964</td>\n      <td>62.722679</td>\n    </tr>\n    <tr>\n      <th>1422</th>\n      <td>Do It To It</td>\n      <td>157890.0</td>\n      <td>91.0</td>\n      <td>78.000000</td>\n      <td>False</td>\n      <td>0.854</td>\n      <td>0.806</td>\n      <td>11.0</td>\n      <td>-8.262</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.155907</td>\n      <td>68.733521</td>\n      <td>-5.703623</td>\n      <td>47.707085</td>\n      <td>-1.433100</td>\n      <td>45.689129</td>\n      <td>-6.835608</td>\n      <td>45.040623</td>\n      <td>-1.940495</td>\n      <td>51.794838</td>\n    </tr>\n  </tbody>\n</table>\n<p>1423 rows × 75 columns</p>\n</div>"
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df = spotify_df.merge(audio_analysis_df, how='inner', on='billboard_name')\n",
    "songs_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "outputs": [
    {
     "data": {
      "text/plain": "         duration_ms  spotify_popularity  spotify_artist_popularity_mean  \\\ncount    1423.000000         1423.000000                     1423.000000   \nmean   200696.557976           67.404076                       83.302977   \nstd     50770.975125           17.661345                       12.018877   \nmin     32000.000000            0.000000                        0.000000   \n25%    170322.000000           64.000000                       78.000000   \n50%    195428.000000           70.000000                       86.000000   \n75%    223599.000000           77.000000                       91.000000   \nmax    613026.000000           95.000000                      100.000000   \n\n       danceability       energy          key     loudness         mode  \\\ncount   1423.000000  1423.000000  1423.000000  1423.000000  1423.000000   \nmean       0.666045     0.622016     5.153197    -6.747289     0.622628   \nstd        0.151579     0.162841     3.600340     2.579960     0.484900   \nmin        0.150000     0.007600     0.000000   -33.663000     0.000000   \n25%        0.570000     0.525000     1.000000    -7.841500     0.000000   \n50%        0.680000     0.633000     5.000000    -6.360000     1.000000   \n75%        0.776000     0.733500     8.000000    -5.077500     1.000000   \nmax        0.965000     0.984000    11.000000    -1.321000     1.000000   \n\n       speechiness  acousticness  ...  mfcc16_mean   mfcc16_var  mfcc17_mean  \\\ncount  1423.000000   1423.000000  ...  1423.000000  1423.000000  1423.000000   \nmean      0.139837      0.223816  ...     2.398114    84.513799    -3.647905   \nstd       0.125819      0.253148  ...     3.631675    24.471115     3.398574   \nmin       0.023200      0.000003  ...   -13.240079    32.670311   -18.392536   \n25%       0.042800      0.031550  ...     0.246056    68.009289    -5.805181   \n50%       0.079800      0.121000  ...     2.442511    81.295982    -3.595455   \n75%       0.218000      0.321500  ...     4.722763    98.500587    -1.416037   \nmax       0.699000      0.995000  ...    13.629806   207.025589     6.795540   \n\n        mfcc17_var  mfcc18_mean   mfcc18_var  mfcc19_mean   mfcc19_var  \\\ncount  1423.000000  1423.000000  1423.000000  1423.000000  1423.000000   \nmean     82.115186     2.668189    80.818220    -2.539943    79.075432   \nstd      24.637780     3.253561    24.665541     3.023733    24.767819   \nmin      31.161884   -10.105947    31.325922   -14.229393    28.560005   \n25%      65.208897     0.716595    64.160015    -4.468847    62.009989   \n50%      78.402687     2.753472    77.774918    -2.510375    75.437561   \n75%      94.838615     4.810408    93.118820    -0.625247    91.067223   \nmax     219.371109    12.521308   229.869766     7.686097   229.040588   \n\n       mfcc20_mean   mfcc20_var  \ncount  1423.000000  1423.000000  \nmean      1.677588    80.371770  \nstd       3.186344    26.740148  \nmin     -13.992401    28.597084  \n25%      -0.239844    61.936447  \n50%       1.633557    75.101379  \n75%       3.652482    93.510078  \nmax      14.772246   226.710175  \n\n[8 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>spotify_popularity</th>\n      <th>spotify_artist_popularity_mean</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>...</th>\n      <th>mfcc16_mean</th>\n      <th>mfcc16_var</th>\n      <th>mfcc17_mean</th>\n      <th>mfcc17_var</th>\n      <th>mfcc18_mean</th>\n      <th>mfcc18_var</th>\n      <th>mfcc19_mean</th>\n      <th>mfcc19_var</th>\n      <th>mfcc20_mean</th>\n      <th>mfcc20_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>...</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>200696.557976</td>\n      <td>67.404076</td>\n      <td>83.302977</td>\n      <td>0.666045</td>\n      <td>0.622016</td>\n      <td>5.153197</td>\n      <td>-6.747289</td>\n      <td>0.622628</td>\n      <td>0.139837</td>\n      <td>0.223816</td>\n      <td>...</td>\n      <td>2.398114</td>\n      <td>84.513799</td>\n      <td>-3.647905</td>\n      <td>82.115186</td>\n      <td>2.668189</td>\n      <td>80.818220</td>\n      <td>-2.539943</td>\n      <td>79.075432</td>\n      <td>1.677588</td>\n      <td>80.371770</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>50770.975125</td>\n      <td>17.661345</td>\n      <td>12.018877</td>\n      <td>0.151579</td>\n      <td>0.162841</td>\n      <td>3.600340</td>\n      <td>2.579960</td>\n      <td>0.484900</td>\n      <td>0.125819</td>\n      <td>0.253148</td>\n      <td>...</td>\n      <td>3.631675</td>\n      <td>24.471115</td>\n      <td>3.398574</td>\n      <td>24.637780</td>\n      <td>3.253561</td>\n      <td>24.665541</td>\n      <td>3.023733</td>\n      <td>24.767819</td>\n      <td>3.186344</td>\n      <td>26.740148</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>32000.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.150000</td>\n      <td>0.007600</td>\n      <td>0.000000</td>\n      <td>-33.663000</td>\n      <td>0.000000</td>\n      <td>0.023200</td>\n      <td>0.000003</td>\n      <td>...</td>\n      <td>-13.240079</td>\n      <td>32.670311</td>\n      <td>-18.392536</td>\n      <td>31.161884</td>\n      <td>-10.105947</td>\n      <td>31.325922</td>\n      <td>-14.229393</td>\n      <td>28.560005</td>\n      <td>-13.992401</td>\n      <td>28.597084</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>170322.000000</td>\n      <td>64.000000</td>\n      <td>78.000000</td>\n      <td>0.570000</td>\n      <td>0.525000</td>\n      <td>1.000000</td>\n      <td>-7.841500</td>\n      <td>0.000000</td>\n      <td>0.042800</td>\n      <td>0.031550</td>\n      <td>...</td>\n      <td>0.246056</td>\n      <td>68.009289</td>\n      <td>-5.805181</td>\n      <td>65.208897</td>\n      <td>0.716595</td>\n      <td>64.160015</td>\n      <td>-4.468847</td>\n      <td>62.009989</td>\n      <td>-0.239844</td>\n      <td>61.936447</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>195428.000000</td>\n      <td>70.000000</td>\n      <td>86.000000</td>\n      <td>0.680000</td>\n      <td>0.633000</td>\n      <td>5.000000</td>\n      <td>-6.360000</td>\n      <td>1.000000</td>\n      <td>0.079800</td>\n      <td>0.121000</td>\n      <td>...</td>\n      <td>2.442511</td>\n      <td>81.295982</td>\n      <td>-3.595455</td>\n      <td>78.402687</td>\n      <td>2.753472</td>\n      <td>77.774918</td>\n      <td>-2.510375</td>\n      <td>75.437561</td>\n      <td>1.633557</td>\n      <td>75.101379</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>223599.000000</td>\n      <td>77.000000</td>\n      <td>91.000000</td>\n      <td>0.776000</td>\n      <td>0.733500</td>\n      <td>8.000000</td>\n      <td>-5.077500</td>\n      <td>1.000000</td>\n      <td>0.218000</td>\n      <td>0.321500</td>\n      <td>...</td>\n      <td>4.722763</td>\n      <td>98.500587</td>\n      <td>-1.416037</td>\n      <td>94.838615</td>\n      <td>4.810408</td>\n      <td>93.118820</td>\n      <td>-0.625247</td>\n      <td>91.067223</td>\n      <td>3.652482</td>\n      <td>93.510078</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>613026.000000</td>\n      <td>95.000000</td>\n      <td>100.000000</td>\n      <td>0.965000</td>\n      <td>0.984000</td>\n      <td>11.000000</td>\n      <td>-1.321000</td>\n      <td>1.000000</td>\n      <td>0.699000</td>\n      <td>0.995000</td>\n      <td>...</td>\n      <td>13.629806</td>\n      <td>207.025589</td>\n      <td>6.795540</td>\n      <td>219.371109</td>\n      <td>12.521308</td>\n      <td>229.869766</td>\n      <td>7.686097</td>\n      <td>229.040588</td>\n      <td>14.772246</td>\n      <td>226.710175</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(songs_df.apply(lambda x: x.nunique()))\n",
    "songs_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "outputs": [
    {
     "data": {
      "text/plain": "billboard_name                    0\nduration_ms                       0\nspotify_popularity                0\nspotify_artist_popularity_mean    0\nexplicit                          0\n                                 ..\nmfcc18_var                        0\nmfcc19_mean                       0\nmfcc19_var                        0\nmfcc20_mean                       0\nmfcc20_var                        0\nLength: 75, dtype: int64"
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [],
   "source": [
    "songs_df = pd.get_dummies(songs_df, prefix=['explicit'], columns=['explicit'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I don't know what made me think we need *MORE* features, but here's more features...\n",
    "Some extra feature engineering for spotify's audio analysis object that did't happen during dataset construction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [],
   "source": [
    "# this code is so slow it hurts me...\n",
    "\n",
    "def spotify_audio_analysis(filename):\n",
    "    file = open(filename)\n",
    "    analysis_json = json.load(file)\n",
    "    file.close()\n",
    "    timbre_coefs = np.arange(13, 1, -1)\n",
    "    bars = analysis_json['bars']\n",
    "    beats = analysis_json['beats']\n",
    "    sections = analysis_json['sections']\n",
    "    segments = analysis_json['segments']\n",
    "    tatums = analysis_json['tatums']\n",
    "\n",
    "    return pd.DataFrame(data={\n",
    "        # \"time_signature\": [analysis_json['track']['time_signature']],\n",
    "        # \"mode\": [analysis_json['track']['mode']],\n",
    "        \"num_bars\": len(bars),\n",
    "        \"mean_bar_duration\": np.mean([b['duration'] for b in bars]),\n",
    "        \"var_bar_duration\": np.var([b['duration'] for b in bars]),\n",
    "        \"num_beats\": len(beats),\n",
    "        \"mean_beat_duration\": np.mean([b['duration'] for b in beats]),\n",
    "        \"var_beat_duration\": np.var([b['duration'] for b in beats]),\n",
    "        \"num_sections\": len(sections),\n",
    "        \"mean_section_duration\": np.mean([s['duration'] for s in sections]),\n",
    "        \"var_section_duration\": np.var([s['duration'] for s in sections]),\n",
    "        \"mean_section_tempo\": np.mean([s['tempo'] for s in sections]),\n",
    "        \"var_section_tempo\": np.var([s['tempo'] for s in sections]),\n",
    "        \"mean_section_loudness\": np.mean([s['loudness'] for s in sections]),\n",
    "        \"var_section_loudness\": np.var([s['loudness'] for s in sections]),\n",
    "        # other section stuff\n",
    "        \"num_segments\": len(segments),\n",
    "        \"mean_segment_duration\": np.mean([s['duration'] for s in segments]),\n",
    "        \"var_segment_duration\": np.var([s['duration'] for s in segments]),\n",
    "        \"mean_segment_loudness_start\": np.mean([s['loudness_start'] for s in segments]),\n",
    "        \"var_segment_loudness_start\": np.var([s['loudness_start'] for s in segments]),\n",
    "        \"mean_segment_loudness_max\": np.mean([s['loudness_max'] for s in segments]),\n",
    "        \"var_segment_loudness_max\": np.var([s['loudness_max'] for s in segments]),\n",
    "        \"mean_segment_loudness_max_time\": np.mean([s['loudness_max_time'] for s in segments]),\n",
    "        \"var_segment_loudness_max_time\": np.var([s['loudness_max_time'] for s in segments]),\n",
    "        \"mean_segment_loudness_end\": np.mean([s['loudness_end'] for s in segments]),\n",
    "        \"var_segment_loudness_end\": np.var([s['loudness_end'] for s in segments]),\n",
    "        \"mean_segment_loudness_start_max_diff\": np.mean([abs(s['loudness_start'] - s['loudness_max']) for s in segments]),\n",
    "        \"var_segment_loudness_start_max_diff\": np.var([abs(s['loudness_start'] - s['loudness_max']) for s in segments]),\n",
    "        \"mean_segment_loudness_start_end_diff\": np.mean([abs(s['loudness_start'] - s['loudness_end']) for s in segments]),\n",
    "        \"var_segment_loudness_start_end_diff\": np.var([abs(s['loudness_start'] - s['loudness_end']) for s in segments]),\n",
    "        \"mean_segment_loudness_max_end_diff\": np.mean([abs(s['loudness_max'] - s['loudness_end']) for s in segments]),\n",
    "        \"var_segment_loudness_max_end_diff\": np.var([abs(s['loudness_max'] - s['loudness_end']) for s in segments]),\n",
    "        \"mean_segment_num_pitches\": np.mean([len(s['pitches']) for s in segments]),\n",
    "        \"var_segment_num_pitches\": np.var([len(s['pitches']) for s in segments]),\n",
    "        \"mean_segment_num_pure_pitches\": np.mean([len(np.array(s['pitches'])[np.array(s['pitches']) > 0.5]) for s in segments]),\n",
    "        \"var_segment_num_pure_pitches\": np.var([len(np.array(s['pitches'])[np.array(s['pitches']) > 0.5]) for s in segments]),\n",
    "        \"mean_segment_timbre\": np.mean([np.dot(s['timbre'], timbre_coefs) for s in segments]),\n",
    "        \"var_segment_timbre\": np.var([np.dot(s['timbre'], timbre_coefs) for s in segments]),\n",
    "        \"num_tatums\": len(tatums),\n",
    "        \"mean_tatum_duration\": np.mean([t['duration'] for t in tatums]),\n",
    "        \"var_tatum_duration\": np.var([t['duration'] for t in tatums]),\n",
    "    }, index=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### This will take a little bit to run"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "outputs": [],
   "source": [
    "aa = pd.DataFrame()\n",
    "for i in range(len(songs_df)):\n",
    "    aa = pd.concat([aa, spotify_audio_analysis(\"../data/spofity/audio_analysis/\" + spotify_df['audio_analysis_file'].iloc[0])], axis=0)\n",
    "aa.reset_index(inplace=True)\n",
    "songs_df = pd.concat([songs_df, aa], axis=1)\n",
    "songs_df.drop(labels='index', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "outputs": [
    {
     "data": {
      "text/plain": "         duration_ms  spotify_popularity  spotify_artist_popularity_mean  \\\ncount    1423.000000         1423.000000                     1423.000000   \nmean   200696.557976           67.404076                       83.302977   \nstd     50770.975125           17.661345                       12.018877   \nmin     32000.000000            0.000000                        0.000000   \n25%    170322.000000           64.000000                       78.000000   \n50%    195428.000000           70.000000                       86.000000   \n75%    223599.000000           77.000000                       91.000000   \nmax    613026.000000           95.000000                      100.000000   \n\n       danceability       energy          key     loudness         mode  \\\ncount   1423.000000  1423.000000  1423.000000  1423.000000  1423.000000   \nmean       0.666045     0.622016     5.153197    -6.747289     0.622628   \nstd        0.151579     0.162841     3.600340     2.579960     0.484900   \nmin        0.150000     0.007600     0.000000   -33.663000     0.000000   \n25%        0.570000     0.525000     1.000000    -7.841500     0.000000   \n50%        0.680000     0.633000     5.000000    -6.360000     1.000000   \n75%        0.776000     0.733500     8.000000    -5.077500     1.000000   \nmax        0.965000     0.984000    11.000000    -1.321000     1.000000   \n\n       speechiness  acousticness  ...  var_segment_loudness_max_end_diff  \\\ncount  1423.000000   1423.000000  ...                       1.423000e+03   \nmean      0.139837      0.223816  ...                       4.533173e+01   \nstd       0.125819      0.253148  ...                       8.316273e-13   \nmin       0.023200      0.000003  ...                       4.533173e+01   \n25%       0.042800      0.031550  ...                       4.533173e+01   \n50%       0.079800      0.121000  ...                       4.533173e+01   \n75%       0.218000      0.321500  ...                       4.533173e+01   \nmax       0.699000      0.995000  ...                       4.533173e+01   \n\n       mean_segment_num_pitches  var_segment_num_pitches  \\\ncount                    1423.0                   1423.0   \nmean                       12.0                      0.0   \nstd                         0.0                      0.0   \nmin                        12.0                      0.0   \n25%                        12.0                      0.0   \n50%                        12.0                      0.0   \n75%                        12.0                      0.0   \nmax                        12.0                      0.0   \n\n       mean_segment_num_pure_pitches  var_segment_num_pure_pitches  \\\ncount                   1.423000e+03                  1.423000e+03   \nmean                    2.263092e+00                  2.966942e+00   \nstd                     3.331840e-14                  6.663680e-14   \nmin                     2.263092e+00                  2.966942e+00   \n25%                     2.263092e+00                  2.966942e+00   \n50%                     2.263092e+00                  2.966942e+00   \n75%                     2.263092e+00                  2.966942e+00   \nmax                     2.263092e+00                  2.966942e+00   \n\n       mean_segment_timbre  var_segment_timbre  num_tatums  \\\ncount         1.423000e+03        1.423000e+03      1423.0   \nmean          1.864666e+03        1.180701e+06      1106.0   \nstd           2.956897e-12        2.049630e-08         0.0   \nmin           1.864666e+03        1.180701e+06      1106.0   \n25%           1.864666e+03        1.180701e+06      1106.0   \n50%           1.864666e+03        1.180701e+06      1106.0   \n75%           1.864666e+03        1.180701e+06      1106.0   \nmax           1.864666e+03        1.180701e+06      1106.0   \n\n       mean_tatum_duration  var_tatum_duration  \ncount         1.423000e+03        1.423000e+03  \nmean          2.157633e-01        6.160453e-03  \nstd           2.832064e-15        7.201633e-17  \nmin           2.157633e-01        6.160453e-03  \n25%           2.157633e-01        6.160453e-03  \n50%           2.157633e-01        6.160453e-03  \n75%           2.157633e-01        6.160453e-03  \nmax           2.157633e-01        6.160453e-03  \n\n[8 rows x 113 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>spotify_popularity</th>\n      <th>spotify_artist_popularity_mean</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>...</th>\n      <th>var_segment_loudness_max_end_diff</th>\n      <th>mean_segment_num_pitches</th>\n      <th>var_segment_num_pitches</th>\n      <th>mean_segment_num_pure_pitches</th>\n      <th>var_segment_num_pure_pitches</th>\n      <th>mean_segment_timbre</th>\n      <th>var_segment_timbre</th>\n      <th>num_tatums</th>\n      <th>mean_tatum_duration</th>\n      <th>var_tatum_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>1423.000000</td>\n      <td>...</td>\n      <td>1.423000e+03</td>\n      <td>1423.0</td>\n      <td>1423.0</td>\n      <td>1.423000e+03</td>\n      <td>1.423000e+03</td>\n      <td>1.423000e+03</td>\n      <td>1.423000e+03</td>\n      <td>1423.0</td>\n      <td>1.423000e+03</td>\n      <td>1.423000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>200696.557976</td>\n      <td>67.404076</td>\n      <td>83.302977</td>\n      <td>0.666045</td>\n      <td>0.622016</td>\n      <td>5.153197</td>\n      <td>-6.747289</td>\n      <td>0.622628</td>\n      <td>0.139837</td>\n      <td>0.223816</td>\n      <td>...</td>\n      <td>4.533173e+01</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.263092e+00</td>\n      <td>2.966942e+00</td>\n      <td>1.864666e+03</td>\n      <td>1.180701e+06</td>\n      <td>1106.0</td>\n      <td>2.157633e-01</td>\n      <td>6.160453e-03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>50770.975125</td>\n      <td>17.661345</td>\n      <td>12.018877</td>\n      <td>0.151579</td>\n      <td>0.162841</td>\n      <td>3.600340</td>\n      <td>2.579960</td>\n      <td>0.484900</td>\n      <td>0.125819</td>\n      <td>0.253148</td>\n      <td>...</td>\n      <td>8.316273e-13</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.331840e-14</td>\n      <td>6.663680e-14</td>\n      <td>2.956897e-12</td>\n      <td>2.049630e-08</td>\n      <td>0.0</td>\n      <td>2.832064e-15</td>\n      <td>7.201633e-17</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>32000.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.150000</td>\n      <td>0.007600</td>\n      <td>0.000000</td>\n      <td>-33.663000</td>\n      <td>0.000000</td>\n      <td>0.023200</td>\n      <td>0.000003</td>\n      <td>...</td>\n      <td>4.533173e+01</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.263092e+00</td>\n      <td>2.966942e+00</td>\n      <td>1.864666e+03</td>\n      <td>1.180701e+06</td>\n      <td>1106.0</td>\n      <td>2.157633e-01</td>\n      <td>6.160453e-03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>170322.000000</td>\n      <td>64.000000</td>\n      <td>78.000000</td>\n      <td>0.570000</td>\n      <td>0.525000</td>\n      <td>1.000000</td>\n      <td>-7.841500</td>\n      <td>0.000000</td>\n      <td>0.042800</td>\n      <td>0.031550</td>\n      <td>...</td>\n      <td>4.533173e+01</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.263092e+00</td>\n      <td>2.966942e+00</td>\n      <td>1.864666e+03</td>\n      <td>1.180701e+06</td>\n      <td>1106.0</td>\n      <td>2.157633e-01</td>\n      <td>6.160453e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>195428.000000</td>\n      <td>70.000000</td>\n      <td>86.000000</td>\n      <td>0.680000</td>\n      <td>0.633000</td>\n      <td>5.000000</td>\n      <td>-6.360000</td>\n      <td>1.000000</td>\n      <td>0.079800</td>\n      <td>0.121000</td>\n      <td>...</td>\n      <td>4.533173e+01</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.263092e+00</td>\n      <td>2.966942e+00</td>\n      <td>1.864666e+03</td>\n      <td>1.180701e+06</td>\n      <td>1106.0</td>\n      <td>2.157633e-01</td>\n      <td>6.160453e-03</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>223599.000000</td>\n      <td>77.000000</td>\n      <td>91.000000</td>\n      <td>0.776000</td>\n      <td>0.733500</td>\n      <td>8.000000</td>\n      <td>-5.077500</td>\n      <td>1.000000</td>\n      <td>0.218000</td>\n      <td>0.321500</td>\n      <td>...</td>\n      <td>4.533173e+01</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.263092e+00</td>\n      <td>2.966942e+00</td>\n      <td>1.864666e+03</td>\n      <td>1.180701e+06</td>\n      <td>1106.0</td>\n      <td>2.157633e-01</td>\n      <td>6.160453e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>613026.000000</td>\n      <td>95.000000</td>\n      <td>100.000000</td>\n      <td>0.965000</td>\n      <td>0.984000</td>\n      <td>11.000000</td>\n      <td>-1.321000</td>\n      <td>1.000000</td>\n      <td>0.699000</td>\n      <td>0.995000</td>\n      <td>...</td>\n      <td>4.533173e+01</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.263092e+00</td>\n      <td>2.966942e+00</td>\n      <td>1.864666e+03</td>\n      <td>1.180701e+06</td>\n      <td>1106.0</td>\n      <td>2.157633e-01</td>\n      <td>6.160453e-03</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 113 columns</p>\n</div>"
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Different Popularity Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "outputs": [],
   "source": [
    "def popularity_metrics(df, score_type='basic'):\n",
    "    metrics = ['peak_rank', 'debut_rank', 'lifetime_peak_rank', 'sensationality', 'avg_rank_score', 'std_rank_score', 'time_on_chart', 'num_occurrences', 'rank_sum', 'skewness', 'kurtosis', 'spotify_popularity']\n",
    "    metric_vals = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        song = df.iloc[i]\n",
    "        billboard_entries = billboard_df[billboard_df['title'] == song['billboard_name']].sort_values(by='date')\n",
    "        value_counts = billboard_entries['rank'].value_counts()\n",
    "        ranks = value_counts.index\n",
    "        rank_counts = value_counts.values\n",
    "\n",
    "        # max rank\n",
    "        peak = min(ranks)\n",
    "        if score_type == 'classic':\n",
    "            ranks = [rank_score_classic(peak, ra) for ra in ranks]\n",
    "            scaled = False\n",
    "        elif score_type == 'score_01':\n",
    "            ranks = [rank_score_01(peak, ra) for ra in ranks]\n",
    "            scaled = True\n",
    "        elif score_type == 'score_02':\n",
    "            ranks = [rank_score_02(peak, ra) for ra in ranks]\n",
    "            scaled = True\n",
    "        else:\n",
    "            ranks = [rank_score_basic(ra) for ra in ranks]\n",
    "            scaled = True\n",
    "\n",
    "        # sensationality\n",
    "        sensation = squiggle(rank_counts, ranks, scaled=scaled)\n",
    "\n",
    "        # mean rank\n",
    "        avg_rank = np.mean(ranks)\n",
    "\n",
    "        # rank std\n",
    "        std_rank = np.std(ranks)\n",
    "\n",
    "        # length\n",
    "        time_on_chart = np.max(billboard_entries['weeks'].values)\n",
    "\n",
    "        # lifetime_peak\n",
    "        lifetime_peak = np.min(billboard_entries['peakPos'].values)\n",
    "\n",
    "        # debut rank\n",
    "        debut_rank = billboard_entries['rank'].iloc[0]\n",
    "\n",
    "        # number of occurrences\n",
    "        num_occurrences = len(billboard_entries)\n",
    "\n",
    "        rank_sum = sum(ranks)\n",
    "\n",
    "        skewness = skew(ranks)\n",
    "\n",
    "        kurt = kurtosis(ranks)\n",
    "\n",
    "        metric_vals.append([peak, debut_rank, lifetime_peak, sensation, avg_rank, std_rank, time_on_chart, num_occurrences, rank_sum, skewness, kurt, song['spotify_popularity']])\n",
    "\n",
    "    return pd.DataFrame(data=metric_vals, columns=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "outputs": [
    {
     "data": {
      "text/plain": "      peak_rank  debut_rank  lifetime_peak_rank  sensationality  \\\n0             1           1                   1        7.161467   \n1             2           2                   2        3.779657   \n2             3           3                   3        2.326703   \n3             4           4                   4        1.668480   \n4             1           5                   1        7.369801   \n...         ...         ...                 ...             ...   \n1418         79          79                  79        0.012658   \n1419         85          85                  85        0.011765   \n1420         91          91                  91        0.010989   \n1421         95          95                  95        0.010526   \n1422         97          97                  97        0.010309   \n\n      avg_rank_score  std_rank_score  time_on_chart  num_occurrences  \\\n0           0.270183        0.316913             50               14   \n1           0.123908        0.156764             44               17   \n2           0.151254        0.099182             41               12   \n3           0.121060        0.075093             25               11   \n4           0.153094        0.215097             61               47   \n...              ...             ...            ...              ...   \n1418        0.012658        0.000000              1                1   \n1419        0.011765        0.000000              1                1   \n1420        0.010989        0.000000              1                1   \n1421        0.010526        0.000000              1                1   \n1422        0.010309        0.000000              1                1   \n\n      rank_sum  skewness  kurtosis  spotify_popularity  \n0     2.161467  1.395650  0.673814                69.0  \n1     1.362990  1.352697  0.450922                62.0  \n2     1.210036  0.477332 -0.985764                62.0  \n3     0.968480  0.378995 -1.307941                54.0  \n4     2.908793  3.182407  9.711951                86.0  \n...        ...       ...       ...                 ...  \n1418  0.012658  0.000000 -3.000000                41.0  \n1419  0.011765  0.000000 -3.000000                66.0  \n1420  0.010989  0.000000 -3.000000                69.0  \n1421  0.010526  0.000000 -3.000000                70.0  \n1422  0.010309  0.000000 -3.000000                91.0  \n\n[1423 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>peak_rank</th>\n      <th>debut_rank</th>\n      <th>lifetime_peak_rank</th>\n      <th>sensationality</th>\n      <th>avg_rank_score</th>\n      <th>std_rank_score</th>\n      <th>time_on_chart</th>\n      <th>num_occurrences</th>\n      <th>rank_sum</th>\n      <th>skewness</th>\n      <th>kurtosis</th>\n      <th>spotify_popularity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7.161467</td>\n      <td>0.270183</td>\n      <td>0.316913</td>\n      <td>50</td>\n      <td>14</td>\n      <td>2.161467</td>\n      <td>1.395650</td>\n      <td>0.673814</td>\n      <td>69.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3.779657</td>\n      <td>0.123908</td>\n      <td>0.156764</td>\n      <td>44</td>\n      <td>17</td>\n      <td>1.362990</td>\n      <td>1.352697</td>\n      <td>0.450922</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2.326703</td>\n      <td>0.151254</td>\n      <td>0.099182</td>\n      <td>41</td>\n      <td>12</td>\n      <td>1.210036</td>\n      <td>0.477332</td>\n      <td>-0.985764</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1.668480</td>\n      <td>0.121060</td>\n      <td>0.075093</td>\n      <td>25</td>\n      <td>11</td>\n      <td>0.968480</td>\n      <td>0.378995</td>\n      <td>-1.307941</td>\n      <td>54.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>7.369801</td>\n      <td>0.153094</td>\n      <td>0.215097</td>\n      <td>61</td>\n      <td>47</td>\n      <td>2.908793</td>\n      <td>3.182407</td>\n      <td>9.711951</td>\n      <td>86.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1418</th>\n      <td>79</td>\n      <td>79</td>\n      <td>79</td>\n      <td>0.012658</td>\n      <td>0.012658</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.012658</td>\n      <td>0.000000</td>\n      <td>-3.000000</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>1419</th>\n      <td>85</td>\n      <td>85</td>\n      <td>85</td>\n      <td>0.011765</td>\n      <td>0.011765</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.011765</td>\n      <td>0.000000</td>\n      <td>-3.000000</td>\n      <td>66.0</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>91</td>\n      <td>91</td>\n      <td>91</td>\n      <td>0.010989</td>\n      <td>0.010989</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.010989</td>\n      <td>0.000000</td>\n      <td>-3.000000</td>\n      <td>69.0</td>\n    </tr>\n    <tr>\n      <th>1421</th>\n      <td>95</td>\n      <td>95</td>\n      <td>95</td>\n      <td>0.010526</td>\n      <td>0.010526</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.010526</td>\n      <td>0.000000</td>\n      <td>-3.000000</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>1422</th>\n      <td>97</td>\n      <td>97</td>\n      <td>97</td>\n      <td>0.010309</td>\n      <td>0.010309</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.010309</td>\n      <td>0.000000</td>\n      <td>-3.000000</td>\n      <td>91.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1423 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_metrics_basic = popularity_metrics(songs_df, 'basic')\n",
    "pop_metrics_basic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "outputs": [],
   "source": [
    "# pop_metrics_classic = popularity_metrics(songs_df, 'classic')\n",
    "# pop_metrics_classic.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "outputs": [],
   "source": [
    "# pop_metrics_score_01 = popularity_metrics(songs_df, 'score_01')\n",
    "# pop_metrics_score_01.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "outputs": [],
   "source": [
    "# pop_metrics_score_02 = popularity_metrics(songs_df, 'score_02')\n",
    "# pop_metrics_score_02.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_df = songs_df.copy()\n",
    "song_billboard_names = data_df.pop('billboard_name')\n",
    "song_audio_analysis_files = data_df.pop('audio_analysis_file')\n",
    "data_df.drop(labels=['spotify_popularity', 'spotify_artist_popularity_mean'], axis=1, inplace=True)\n",
    "data_df[data_df.columns] = StandardScaler().fit_transform(data_df)\n",
    "# data_df.to_csv(\"../data/data.csv\")\n",
    "# pop_metrics_basic.to_csv(\"../data/popularity_metrics.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_metrics = pop_metrics_basic\n",
    "pop_metrics[pop_metrics.columns] = StandardScaler().fit_transform(pop_metrics)\n",
    "\n",
    "sns.distplot(pop_metrics['skewness'])\n",
    "pp_x = data_df\n",
    "pp_met = pop_metrics\n",
    "pop_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "pop_metrics['sen_range'] = pop_metrics['avg_rank_score'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "pp_met_pos = pop_metrics[pop_metrics['sen_range'] == 1]\n",
    "pp_met_neg = shuffle(pop_metrics[pop_metrics['sen_range'] == 0]).head(len(pp_met_pos))\n",
    "pp_met = pd.concat([pp_met_pos, pp_met_neg])\n",
    "pp_x = data_df.iloc[pp_met.index]\n",
    "\n",
    "sns.distplot(pp_met['avg_rank_score'])\n",
    "\n",
    "# sns.countplot(pp_met['sen_range'])\n",
    "# y_col = 'sensationality'\n",
    "# y = data_df.pop(y_col)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.sort(pop_metrics['skewness'])\n",
    "f_x = np.gradient(x)*np.exp(-x**2/2)\n",
    "sample_probs = f_x/np.sum(f_x)\n",
    "# samples = np.random.choice(x, p=sample_probs, size=1000000)\n",
    "df_samples = pop_metrics[\"skewness\"].sort_values().sample(\n",
    "    n=400,\n",
    "    weights=sample_probs,\n",
    "    replace=False,\n",
    ")\n",
    "\n",
    "sns.distplot(df_samples)\n",
    "# df_samples\n",
    "pp_met = pop_metrics.iloc[df_samples.index]\n",
    "pp_x = data_df.iloc[df_samples.index]\n",
    "# song_billboard_names = songs_df[df_samples.index]\n",
    "\n",
    "# pop_metrics[pop_metrics[\"sensationality\"] > 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "\n",
    "# pop_metrics = [pop_metrics_basic, pop_metrics_classic, pop_metrics_score_01, pop_metrics_score_02]\n",
    "# for pms in pop_metrics:\n",
    "#     ln = LinearRegression()\n",
    "#     param_map = {\"y\": [pms[pm] for pm in pms.columns]}\n",
    "#     print(gscv(ln, param_map, data_df.values, score_method='neg_root_mean_squared_error'))\n",
    "\n",
    "def process_subset(model, X, y, features):\n",
    "    kf = KFold()\n",
    "    mse = []\n",
    "    X = X[list(features)]\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        regr = model.fit(X_train, y=y_train)\n",
    "        y_predict = regr.predict(X_test)\n",
    "        mse.append(mean_squared_error(y_test, y_predict))\n",
    "    return {\"model\": model, \"features\": features, \"MSE\":np.mean(mse)}\n",
    "\n",
    "def best_subset(model, X, y, subset_size=-1, force=False):\n",
    "    limit = 100000\n",
    "    if subset_size == -1:\n",
    "        subset_size = len(X.columns)\n",
    "    assert len(X.columns) >= subset_size, f\"X.columns must be >= subset_size. Given len(X.columns)={len(X.columns)}, subset_size={subset_size}\"\n",
    "\n",
    "    num_combinations = np.math.factorial(len(X.columns))/(np.math.factorial(len(X.columns)-subset_size) * np.math.factorial(subset_size))\n",
    "    if num_combinations > limit and not force:\n",
    "        print(f\"Please be aware that this action run {int(num_combinations)} models and there is a real possibility it will crash your machine.\\nIf you're sure you want to do this please include the parameter 'force=True' when calling this function\")\n",
    "        return {\"model\": model, \"features\": X.columns, \"MSE\": 2}\n",
    "    tic = time.time()\n",
    "    results = []\n",
    "    for combo in itertools.combinations(X.columns, subset_size):\n",
    "        results.append(process_subset(model, X, y, combo))\n",
    "    models = pd.DataFrame(results)\n",
    "    best_model = models.loc[models['MSE'].argmin()]\n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", subset_size, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    return best_model\n",
    "\n",
    "# def forward(model, X, y, staring_predictors):\n",
    "#     remaining_predictors = [p for p in X.columns if p not in staring_predictors]\n",
    "#     tic = time.time()\n",
    "#     results = []\n",
    "#     for p in remaining_predictors:\n",
    "#         results.append(process_subset(model, X, y, staring_predictors+[p]))\n",
    "#     models = pd.DataFrame(results)\n",
    "#     best_model = models.loc[models['MSE'].argmin()]\n",
    "#     toc = time.time()\n",
    "#     print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "#\n",
    "#     Return the best model, along with some other useful information about the model\n",
    "    # return best_model\n",
    "\n",
    "# all_features = ['duration_ms', 'key', 'energy', 'loudness', 'danceability', 'speechiness', 'instrumentalness', 'tempo']\n",
    "pp_x = pp_x.filter(regex=('^((?!mfcc).)*$'))\n",
    "\n",
    "best_model = best_subset(LinearRegression(), pp_x, pp_met['avg_rank_score'], -1)\n",
    "print(f\"Best Features: f{best_model['features']}\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(pp_x[list(best_model['features'])], pp_met['avg_rank_score'])\n",
    "mdl = LinearRegression().fit(x_train, y_train)\n",
    "y_pred = mdl.predict(x_test)\n",
    "print(f\"mse: {mean_squared_error(y_test, y_pred)}\")\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.plot(y_test,y_test,'r', label='test')\n",
    "plt.plot(y_pred,y_pred,'b', label='pred')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "pca_data = pca.fit_transform(data_df)\n",
    "\n",
    "pca_comp = pd.DataFrame(pca.components_, index=pca_data.index)\n",
    "pca_comp.style.background_gradient(vmin=-1, vmax=1, cmap=sns.color_palette(\"vlag\", as_cmap=True))\n",
    "pca_comp.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_comp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. All 111 or 71 if mfccs are left out\n",
    "2. 1 model with forward regression\n",
    "3. 1 model with backward regression\n",
    "4. best 2 models with best subset with len=avg(forward and backward)\n",
    "5. Limit our initial feature set => data visualisations and exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}